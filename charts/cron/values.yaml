global:
  aws:
    # global.aws.accountId -- The AWS account that this application is being deployed into
    # @default -- Taken from deployment pipeline environment
    # @section -- global
    accountId: ""

  serviceAccount:
    # global.serviceAccount.enabled -- Set to `false` to prevent the `ServiceAccount` from being created
    # @section -- global
    enabled: true

    # global.serviceAccount.name -- `ServiceAccount` name. Use with `global.serviceAccount.enabled: false`
    # to use an existing `ServiceAccount`
    # @default -- `.Release.Name`
    # @section -- global
    name: ""

    # global.serviceAccount.automountServiceAccountToken -- Set to `true` to mount tokens for access to the Kubernetes API. This should almost always be `false`
    # @section -- global
    automountServiceAccountToken: false

    # global.serviceAccount.annotations -- Set annotations on the `ServiceAccount`
    # @section -- global
    annotations: {}

image:
  # image.name -- The container image of your application
  # @section -- application
  name: "public.ecr.aws/nginx/nginx"

  # image.tag -- The tag for the image that you want to deploy
  # @section -- application
  tag: "alpine"

cron:
  # cron.schedule -- Cron formatted schedule for job
  # @section -- cron
  schedule: "0 1 31 2 *"

  # cron.timeZone -- A valid IANA TZ name
  # @section -- cron
  timeZone: "Europe/London"

  # cron.concurrencyPolicy -- WHether or not to allow the cron to overlap with the previous run. Valid values are: `Allow`, `Forbid` or `Replace`
  # @section -- cron
  concurrencyPolicy: Forbid

  # cron.retries -- Number of retries on failure of job
  # @section -- cron
  retries: 0

  # cron.parallelism -- Number of pods of the cron job to start
  # @section -- cron
  parallelism: 1

  # cron.command -- Command to run on the image. e.g [/bin/bash, my-script.sh]
  # @section -- application
  command: []

  # cron.args -- Arguments for the command
  # @section -- application
  args: []

  # cron.restartPolicy -- Whether or not the pod should restart on failure. Valid values are: `Never` or `onFailure`
  # @section -- cron
  restartPolicy: Never

  # cron.timeoutSeconds -- The maximum amount of time the job should run for in seconds.
  # @section -- cron
  timeoutSeconds: 86400

# env -- **Non-secret** environment variables to configure your application. Formatted as `ENV_VAR_NAME: env-var-value`
# @section -- application
env: {}

# envFrom -- Create environment variables from `Secret` or `ConfigMap` resources.
# See https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/
# @section -- application
envFrom: []

# secretEnv -- Secret values that are mounted as environment variables. Formatted as `ENV_VAR_NAME: env-var-value`
# in a SOPS encrypted `secrets.yaml` file
# @section -- application
secretEnv: {}

# secretVolume -- Secret values that will be available as files in `/secrets` inside the container.
# Formatted as `file.name: <base64 encoded file>`
# @section -- application
secretVolume: {}

resources:
  # resources.cpu -- Requested CPU time for the pod
  # @section -- application
  cpu: "100m"

  # resources.memory -- Maximum memory usage for the pod
  # @section -- application
  memory: "64Mi"

pod:
  # pod.additionalVolumes -- Configuration for additional volumes. See example in values.yaml
  additionalVolumes: []
  # - name: dsdsocket
  #   hostPath:
  #     path: /var/run/statsd-exporter

  # pod.additionalVolumeMounts -- Configuration for additional volume mounts. References additionalVolumes, see example in values.yaml
  additionalVolumeMounts: []
  # - name: dsdsocket
  #   mountPath: /socket

  # pod.labels -- Additional labels to add to pods
  labels: {}

  # pod.annotations -- Additional annotations to add to pods
  annotations: {}

  # pod.nodeSelector -- Set a nodeSelector(s) on your pods
  nodeSelector: {}

infra:
  postgres:
    # infra.postgres.enabled -- Set to `true` to deploy a `PostgresInstance` resource
    # @section -- infra
    enabled: false

    # infra.postgres.create -- Set to `false` to skip creation of the `PostgresInstance` if it has been created elsewhere
    # @section -- infra
    create: false

    # infra.postgres.nameOverride -- Override the `PostgresInstance` name or use with `create: false` to map the secrets of an instance created elsewhere
    # @section -- infra
    nameOverride: ""

  s3Bucket:
    # infra.s3Bucket.enabled -- Set to `true` to deploy an `s3Bucket` resource
    # @section -- infra
    enabled: false

    # infra.s3Bucket.create -- Set to `false` to skip creation of the `s3Bucket` if it has been created elsewhere
    # @section -- infra
    create: false

    # infra.s3Bucket.nameOverride -- Override the `s3Bucket` name or use with `create: false` to map the secrets of an instance created elsewhere
    # @section -- infra
    nameOverride: ""

  bedrock:
    # infra.bedrock.enabled -- Set to `true` to deploy an IAM policy and role to be attached to your application to enable bedrock access.
    # @section -- infra
    enabled: false

  eventing:
    producer:
      # infra.eventing.producer.enabled -- Set to `true` to deploy an IAM policy and role to be attached to your application to enable eventbridge access.
      # @section -- infra
      enabled: false

      # infra.eventing.producer.eventBusName -- The EventBridge Bus name that applications should send to.
      # @section -- infra
      # @ignored
      eventBusName: "portswigger"

    consumer:
      # infra.eventing.consumer.enabled -- Set to `true` to deploy an eventrule.
      # @section -- infra
      enabled: false

      # See https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html
      # infra.eventing.consumer.eventPattern -- The pattern the rule should use to decide whether to send an event
      # @section -- infra
      eventPattern: ""

      # See https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-transform-target-input.html#eb-transform-input-examples
      # infra.eventing.consumer.inputPath -- An optional method to extract specific data from events
      # @section -- infra
      inputPath: ""

  dynamodb:
    # infra.dynamodb.create -- Set to `false` to skip creation of the dynamodb tables if they have been created elsewhere
    # @section -- infra
    create: false
    # infra.dynamodb.nameOverride -- Use with `create: false` to grant a policy access to tables created elsewhere
    # @section -- infra
    prefixOverride: ""
    # infra.dynamodb.tables -- A list containing details about dynamodb tables
    # @section -- infra
    tables: []

  opensearch:
    # infra.opensearch.create -- Set to `false` to skip creation of the opensearch collection if it has been created elsewhere
    # @section -- infra
    create: false
    # infra.opensearch.nameOverride -- Use with `create: false` to map the secrets of an instance created elsewhere
    # @section -- infra
    nameOverride: ""
    # infra.opensearch.enabled -- Set to `true` to deploy an opensearch collection
    # @section -- infra
    enabled: false
    # infra.opensearch.type -- The type of the collection. Must be either TIMESERIES, VECTORSEARCH, or SEARCH
    # @section -- infra
    type: "TIMESERIES"
    # infra.opensearch.lifecycleRules -- A list of rules configuring the retention period of indexes
    # @section -- infra
    lifecycleRules: [ ]
  #    - resource: "examples/*"
  #      retainIndefinitely: false
  #      retentionPeriod: "15d"